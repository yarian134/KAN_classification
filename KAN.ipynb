{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "class KANLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        base_activation=tf.keras.activations.silu,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            tf.range(-spline_order, grid_size + spline_order + 1, dtype=tf.float32) * h\n",
        "            + grid_range[0]\n",
        "        )\n",
        "        self.grid = tf.Variable(grid[None, :], trainable=False, dtype=tf.float32)\n",
        "\n",
        "        self.spline_weight = self.add_weight(\n",
        "            shape=(in_features, out_features, grid_size + spline_order),\n",
        "            initializer=tf.keras.initializers.HeUniform(),\n",
        "            trainable=True,\n",
        "            name=\"spline_weight\"\n",
        "        )\n",
        "\n",
        "\n",
        "        self.base_activation = base_activation\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "    def b_splines(self, x):\n",
        "        x = tf.expand_dims(x, axis=-1)\n",
        "        bases = tf.cast((x >= self.grid[:, :-1]) & (x < self.grid[:, 1:]), x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - self.grid[:, : -(k + 1)])\n",
        "                / (self.grid[:, k:-1] - self.grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (self.grid[:, k + 1 :] - x)\n",
        "                / (self.grid[:, k + 1 :] - self.grid[:, 1 : (-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "        return bases\n",
        "\n",
        "    def curve2coeff(self, x, y):\n",
        "        A = tf.transpose(self.b_splines(x), perm=[1, 0, 2])\n",
        "        B = tf.transpose(y, perm=[1, 0, 2])\n",
        "        solution = tf.linalg.lstsq(A, B)\n",
        "        result = tf.transpose(solution, perm=[2, 0, 1])\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "      # Calculate B-spline output and ensure shapes match for matmul\n",
        "      b_splines_output = self.b_splines(x)\n",
        "      batch_size = tf.shape(x)[0]\n",
        "\n",
        "      # Flatten b_splines output appropriately and reshape scaled_spline_weight to match\n",
        "      spline_output = tf.matmul(\n",
        "          tf.reshape(b_splines_output, (batch_size, -1)),\n",
        "          tf.reshape(self.spline_weight, (-1, self.out_features))\n",
        "      )\n",
        "\n",
        "      return  spline_output\n",
        "\n",
        "\n",
        "\n",
        "class KAN(tf.keras.Model):\n",
        "    def __init__(self, layer_sizes, **kwargs):\n",
        "        super(KAN, self).__init__()\n",
        "        self.kan_layers = [KANLayer(layer_sizes[i], layer_sizes[i + 1], **kwargs) for i in range(len(layer_sizes) - 1)]\n",
        "\n",
        "    def call(self, x, update_grid=False):\n",
        "        for layer in self.kan_layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def train(self,X_train,y_train):\n",
        "\n",
        "      train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100).batch(16)\n",
        "\n",
        "\n",
        "      # Training Loop\n",
        "      epochs = 10\n",
        "      for epoch in range(epochs):\n",
        "          # Training\n",
        "          val_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "          for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n",
        "              with tf.GradientTape() as tape:\n",
        "                  logits = self(x_batch_train, training=True)\n",
        "                  loss_value = loss_fn(y_batch_train, logits)\n",
        "              grads = tape.gradient(loss_value, self.trainable_weights)\n",
        "              optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "              val_acc.update_state(y_batch_train,logits)\n",
        "          print(f\"Epoch {epoch + 1},  Accuracy: {val_acc.result().numpy():.4f}\")\n",
        "\n",
        "    def accuracy(self,x_val,y_val):\n",
        "      val_data = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(16)\n",
        "      val_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "      for step, (x_batch_val, y_batch_val) in enumerate(val_data):\n",
        "          logits = self(x_batch_val, training=False)\n",
        "          val_acc.update_state(y_batch_val,logits)\n",
        "      return val_acc.result().numpy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h2JEx3OFwPma"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_excel('sheet.xlsx', sheet_name='Toxicity')\n",
        "data = data.drop(['SMILES'], axis=1)\n",
        "data.dropna(inplace=True, axis=0)\n",
        "y = data['CYTOTOXIC_TO_ALL'].values\n",
        "x = data.drop(['CYTOTOXIC_TO_ALL'], axis=1).values\n",
        "\n",
        "# Split data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "model=KAN([14,4,2])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.train(X_train,y_train)\n",
        "\n",
        "y_pred=model.predict(X_val)\n",
        "y_pred\n",
        "y=np.argmax(y_pred,axis=1)\n",
        "print(y)\n",
        "print(y_val)\n",
        "acc=model.accuracy(X_val,y_val)\n",
        "print(\"Test Accuracy : \",acc)"
      ],
      "metadata": {
        "id": "74eOP3zAwP_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3783cc-ea9e-40da-cfb9-45fd8af55602"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1,  Accuracy: 0.5132\n",
            "Epoch 2,  Accuracy: 0.8289\n",
            "Epoch 3,  Accuracy: 0.8618\n",
            "Epoch 4,  Accuracy: 0.8684\n",
            "Epoch 5,  Accuracy: 0.8750\n",
            "Epoch 6,  Accuracy: 0.8882\n",
            "Epoch 7,  Accuracy: 0.9079\n",
            "Epoch 8,  Accuracy: 0.9276\n",
            "Epoch 9,  Accuracy: 0.9276\n",
            "Epoch 10,  Accuracy: 0.9342\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0]\n",
            "Test Accuracy :  0.8684211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "m = KAN([4, 64, 3])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "m.train(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_pred=m.predict(X_val)\n",
        "y_pred\n",
        "y=np.argmax(y_pred,axis=1)\n",
        "print(y)\n",
        "print(y_val)\n",
        "acc=m.accuracy(X_val,y_val)\n",
        "print(\"Test Accuracy : \",acc)"
      ],
      "metadata": {
        "id": "I4Z198_ANYL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c50bb01-9692-4acc-88eb-53edbebf0083"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1,  Accuracy: 0.2583\n",
            "Epoch 2,  Accuracy: 0.7500\n",
            "Epoch 3,  Accuracy: 0.9250\n",
            "Epoch 4,  Accuracy: 0.9500\n",
            "Epoch 5,  Accuracy: 0.9583\n",
            "Epoch 6,  Accuracy: 0.9583\n",
            "Epoch 7,  Accuracy: 0.9583\n",
            "Epoch 8,  Accuracy: 0.9667\n",
            "Epoch 9,  Accuracy: 0.9667\n",
            "Epoch 10,  Accuracy: 0.9667\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "Test Accuracy :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0IoG91itZmP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}